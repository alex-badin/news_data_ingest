{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexbadin/miniconda3/envs/db_prep/lib/python3.11/site-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import pinecone\n",
    "import json\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "\n",
    "keys_path = '../keys/'\n",
    "data_path = '../../TG_messages/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(keys_path+'api_keys.json') as f:\n",
    "  data = json.loads(f.read())\n",
    "\n",
    "#load openai credentials\n",
    "openai_key = data['openai_key']\n",
    "\n",
    "# load pinecone credentials\n",
    "pine_key = data['pine_key']\n",
    "pine_env = data['pine_env']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Create pinecone DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect downloaded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f3cc62dc7b54846a177854f22b3911b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# collect all df's' into json\n",
    "\n",
    "# set start date\n",
    "start_date = pd.Timestamp(datetime.datetime.now() - datetime.timedelta(days=30), tz='UTC')\n",
    "\n",
    "files = os.listdir(data_path)\n",
    "df_list = []\n",
    "missed_channels = []\n",
    "\n",
    "files = os.listdir(data_path)\n",
    "for file in tqdm_notebook(files):\n",
    "    if file.endswith('.pkl'):\n",
    "        # try to load df\n",
    "        try:\n",
    "            df_temp = pd.read_pickle(data_path+file)\n",
    "        except: \n",
    "            missed_channels.append(file)\n",
    "            continue\n",
    "        # if df empty, skip\n",
    "        if df_temp.shape[0] == 0:\n",
    "            continue\n",
    "        # select data for last 30 days\n",
    "        df_temp = df_temp[df_temp['date'] >= start_date]\n",
    "        # id as channel_id + message_id\n",
    "        df_temp['id'] = df_temp['channel'] + '_' + df_temp['id'].astype(str)\n",
    "        df_temp = df_temp[['id', 'channel','stance', 'date', 'message', 'views', 'cleaned_message', 'summary', 'embeddings']]\n",
    "        df_list.append(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missed_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40714, 9),\n",
       " Timestamp('2023-10-01 00:00:15+0000', tz='UTC'),\n",
       " Timestamp('2023-10-17 12:19:13+0000', tz='UTC'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4pine = pd.concat(df_list)\n",
    "df4pine.shape, df4pine.date.min(), df4pine.date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24728594586628677"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4pine.embeddings.isnull().sum() / df4pine.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears most of news were processed without boost script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating openai embeds\n",
    "To create embeddings faster need json file as per requs in api_request_parallel_processor.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df4pine to json in following format:\n",
    "# {\"model\": \"text-embedding-ada-002\", \"input\": text}\n",
    "model = \"text-embedding-ada-002\"\n",
    "# convert df4pine to json\n",
    "json_list = []\n",
    "for i in tqdm(range(df4pine.shape[0])):\n",
    "    json_dict = {}\n",
    "    json_dict[\"model\"] = model\n",
    "    json_dict[\"input\"] = df4pine.iloc[i]['summary']\n",
    "    json_dict[\"id\"] = df4pine.iloc[i]['id']\n",
    "    json_list.append(json_dict)\n",
    "\n",
    "# save json_list to jsonl\n",
    "import json\n",
    "with open('df4pine.jsonl', 'w') as f:\n",
    "    for item in json_list:\n",
    "        json.dump(item, f)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeds were acquired via script and saved into df4pine_embeds.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check what data we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40714, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open df4pine.jsonl as df\n",
    "df4pine_jsonl = pd.read_json('df4pine_embeds.jsonl', lines=True)\n",
    "df4pine_jsonl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'text-embedding-ada-002',\n",
       " 'input': 'ХАМАС также заявил о запуске сотни ракет в направлении Ашкелона на юге Израиля. ▪Иранские службы безопасности помогли палестинскому исламистскому движению ХАМАС спланировать атаку на Израиль, сообщает The Wall Street Journal. ▪Власти Израиля после нападения со стороны палестинского движения ХАМАС обратились к США с просьбой помочь с пополнением запасов ракет-перехватчиков для системы противоракетной обороны «Железный купол», бомб малого диаметра и боеприпасов для пулеметов, сообщает The Washington Post.',\n",
       " 'id': 'rbc_news_82590'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4pine_jsonl[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['object', 'data', 'model', 'usage'])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df4pine_jsonl[1][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['object', 'index', 'embedding'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4pine_jsonl[1][0]['data'][-1].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare data for pinecone\n",
    "- date to int\n",
    "- add new embeds from json\n",
    "- convert to pinecone format (id, values, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date to integer (without time)\n",
    "df4pine['date'] = df4pine['date'].dt.date\n",
    "df4pine['date'] = df4pine['date'].apply(lambda x: int(time.mktime(x.timetuple())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine all embeds with df4pine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df from df4pine_jsonl with id and embeddings\n",
    "df_new_embeds = pd.DataFrame()\n",
    "df_new_embeds['id_new'] = df4pine_jsonl[0].apply(lambda x: x['id'])\n",
    "df_new_embeds['values'] = df4pine_jsonl[1].apply(lambda x: x['data'][-1]['embedding'])\n",
    "# add embeddings from df4pine_jsonl to df4pine\n",
    "df4pine = df4pine.merge(df_new_embeds, left_on='id', right_on='id_new', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if id's & embeddings are same\n",
    "df4pine.id.equals(df4pine.id_new), df4pine[:1000].embeddings.equals(df4pine[:1000].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings do not match. Because initially were calculated on cleaned message and next time on summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need only columns: id, embeddings and meta as dictionary of clean_message, summary, stance, channel, date, views\n",
    "df4pine['metadata'] = df4pine[['cleaned_message', 'summary', 'stance', 'channel', 'date', 'views']].to_dict('records')\n",
    "df4pine.drop(columns=['id_new', 'embeddings', 'message', 'cleaned_message', 'summary', 'stance', 'channel', 'date', 'views'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40714, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>values</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40711</th>\n",
       "      <td>readovkanews_67921</td>\n",
       "      <td>[-0.03213842, -0.011505554000000001, 0.0026594...</td>\n",
       "      <td>{'cleaned_message': 'Владимир Путин провел вст...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40712</th>\n",
       "      <td>readovkanews_67922</td>\n",
       "      <td>[0.012027255, 0.008897582000000001, -0.0068607...</td>\n",
       "      <td>{'cleaned_message': 'Статью экс-помощника през...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40713</th>\n",
       "      <td>readovkanews_67923</td>\n",
       "      <td>[-0.027030565000000003, -0.012685874000000001,...</td>\n",
       "      <td>{'cleaned_message': 'В Химках дети мигрантов б...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                                             values  \\\n",
       "40711  readovkanews_67921  [-0.03213842, -0.011505554000000001, 0.0026594...   \n",
       "40712  readovkanews_67922  [0.012027255, 0.008897582000000001, -0.0068607...   \n",
       "40713  readovkanews_67923  [-0.027030565000000003, -0.012685874000000001,...   \n",
       "\n",
       "                                                metadata  \n",
       "40711  {'cleaned_message': 'Владимир Путин провел вст...  \n",
       "40712  {'cleaned_message': 'Статью экс-помощника през...  \n",
       "40713  {'cleaned_message': 'В Химках дети мигрантов б...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df4pine.shape)\n",
    "df4pine.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cleaned_message': '17-ого октября в 15:45 в Московском городском суде состоится судебное заседание по поводу апелляции И.И. Стрелкова.',\n",
       " 'summary': '17-ого октября в 15:45 в Московском городском суде состоится судебное заседание по поводу апелляции И.И. Стрелкова.',\n",
       " 'stance': 'voenkor',\n",
       " 'channel': 'strelkovii',\n",
       " 'date': 1696881600,\n",
       " 'views': 283345.0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4pine.metadata[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsert to pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.32058,\n",
       " 'namespaces': {'': {'vector_count': 32058}},\n",
       " 'total_vector_count': 32058}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone.init(api_key=pine_key, environment=pine_env)\n",
    "index_name = 'tg-news'\n",
    "\n",
    "index = pinecone.Index(index_name)\n",
    "\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IndexDescription(name='tg-news', metric='cosine', replicas=1, dimension=1536.0, shards=1, pods=1, pod_type='starter', status={'ready': True, 'state': 'Ready'}, metadata_config=None, source_collection='')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describe index\n",
    "pinecone.describe_index('tg-news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c0ecdc0a77e4595b76439e4eef3ba8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/408 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bath_size = 100\n",
    "for i in tqdm_notebook(range(0, df4pine.shape[0], bath_size)):\n",
    "    index.upsert(vectors=df4pine.iloc[i:i+bath_size].to_dict('records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.41813,\n",
       " 'namespaces': {'': {'vector_count': 41813}},\n",
       " 'total_vector_count': 41813}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['strelkovii', '6386']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4pine['id'][0].split('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2410        lentadnya\n",
       "32386         BFMnews\n",
       "33806      rentv_news\n",
       "5592         izvestia\n",
       "28922      zvezdanews\n",
       "             ...     \n",
       "34640      rentv_news\n",
       "894      breakingmash\n",
       "37198     tass_agency\n",
       "20051        truekpru\n",
       "28485      zvezdanews\n",
       "Name: id, Length: 100, dtype: object"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get last digits from id\n",
    "df4pine['id'].apply(lambda x: x.split('_')[-1]).sample(100)\n",
    "df4pine['id'].apply(lambda x: '_'.join(x.split('_')[:-1])).sample(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Updating pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import unicodedata\n",
    "import time\n",
    "\n",
    "import openai\n",
    "import pinecone\n",
    "from telethon import TelegramClient\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "\n",
    "keys_path = '../keys/'\n",
    "data_path = '../../TG_messages/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(keys_path+'api_keys.json') as f:\n",
    "  data = json.loads(f.read())\n",
    "\n",
    "# load TG credentials\n",
    "api_id = data['api_id'] \n",
    "api_hash = data['api_hash']\n",
    "phone = data['phone']\n",
    "\n",
    "#load openai credentials\n",
    "openai_key = data['openai_key']\n",
    "\n",
    "# load pinecone credentials\n",
    "pine_key = data['pine_key']\n",
    "pine_env = data['pine_env']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions\n",
    "1) Identify which data to download:\n",
    "- by date\n",
    "- by id\n",
    "Anyway need to store last date or id. So let's keep it last_id.\n",
    "\n",
    "2) Remove duplicates in pinecone \n",
    "- they should not be there as id is exactly channel + message_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps (per each channel):\n",
    "- identify last_id (channels.csv)\n",
    "- download from TG as per last_id\n",
    "- process messages: cleaning, deduplicating, summary\n",
    "- create embeds from openai\n",
    "- transform into pinecone format\n",
    "- upsert into pinecone\n",
    "- update last_id in channels.csv\n",
    "- create session_stats file\n",
    "- update total_stats file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>channel_name</th>\n",
       "      <th>channel_code</th>\n",
       "      <th>last_id</th>\n",
       "      <th>ignore</th>\n",
       "      <th>media_type</th>\n",
       "      <th>website</th>\n",
       "      <th>content_type</th>\n",
       "      <th>audience size</th>\n",
       "      <th>stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://t.me/rt_russian</td>\n",
       "      <td>rt_russian</td>\n",
       "      <td>RT</td>\n",
       "      <td>176223</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tv</td>\n",
       "      <td>rt.com</td>\n",
       "      <td>propaganda</td>\n",
       "      <td>105.0</td>\n",
       "      <td>tv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://t.me/ntvnews</td>\n",
       "      <td>ntvnews</td>\n",
       "      <td>NTV</td>\n",
       "      <td>122479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tv</td>\n",
       "      <td>ntv.ru</td>\n",
       "      <td>propaganda</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://t.me/tvrussia1</td>\n",
       "      <td>tvrussia1</td>\n",
       "      <td>ROS1</td>\n",
       "      <td>24043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>propaganda</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      link channel_name channel_code  last_id  ignore  \\\n",
       "0  https://t.me/rt_russian   rt_russian           RT   176223     NaN   \n",
       "1     https://t.me/ntvnews      ntvnews          NTV   122479     NaN   \n",
       "2   https://t.me/tvrussia1    tvrussia1         ROS1    24043     NaN   \n",
       "\n",
       "  media_type website content_type  audience size stance  \n",
       "0         tv  rt.com   propaganda          105.0     tv  \n",
       "1         tv  ntv.ru   propaganda            NaN     tv  \n",
       "2         tv     NaN   propaganda            NaN     tv  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_channels = pd.read_csv('channels.csv', sep=';')\n",
    "df_channels.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Unicode range for emojis\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               \"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "                               \"\\U0001F300-\\U0001F5FF\"  # Symbols & Pictographs\n",
    "                               \"\\U0001F680-\\U0001F6FF\"  # Transport & Map Symbols\n",
    "                               \"\\U0001F1E0-\\U0001F1FF\"  # Flags (iOS)\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    \n",
    "    # Remove emojis\n",
    "    text = emoji_pattern.sub(r'', str(text))\n",
    "\n",
    "    # Regular expression for URLs\n",
    "    url_pattern = re.compile(r\"http\\S+|www\\S+\")\n",
    "        \n",
    "    # Remove URLs\n",
    "    text = url_pattern.sub(r'', str(text))\n",
    "    \n",
    "    # Remove any remaining variation selectors\n",
    "    text = ''.join(char for char in text if unicodedata.category(char) != 'Mn')\n",
    "\n",
    "    #Remove Foreign Agent text    \n",
    "    pattern = re.compile(r'[А-ЯЁ18+]{3,}\\s[А-ЯЁ()]{5,}[^\\n]*ИНОСТРАННОГО АГЕНТА')\n",
    "    text = pattern.sub('', text)\n",
    "    name1 = 'ПИВОВАРОВА АЛЕКСЕЯ ВЛАДИМИРОВИЧА'\n",
    "    text = text.replace(name1, '')\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize the news (select 2 most important sentences)\n",
    "def summarize(text, language=\"russian\", sentences_count=2):\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(language))\n",
    "    summarizer = LsaSummarizer()\n",
    "    summary = summarizer(parser.document, sentences_count)\n",
    "    return ' '.join([str(sentence) for sentence in summary])\n",
    "\n",
    "# NEED MORE FLEXIBLE MODEL\n",
    "# summarize the news - need to keep length upto 750 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_new_messages(df, channel, stance):\n",
    "    df = df.drop_duplicates(subset=['id']).copy() # create a copy of the DataFrame before modifying it\n",
    "    df.loc[:, 'cleaned_message'] = df['message'].apply(clean_text) #remove emojis, urls, foreign agent text\n",
    "    df = df[~df.cleaned_message.str.len().between(0, 30)] #remove empty or too short messages\n",
    "    # summarize cleaned_messages: 2 sentences if length > 750, 3 sentences if length > 1500\n",
    "    df.loc[:, 'summary'] = df['cleaned_message'].apply(lambda x: summarize(x, sentences_count=3) if len(x) > 750 else summarize(x, sentences_count=2) if len(x) > 500 else x)\n",
    "    # add channel name & stance\n",
    "    df.loc[:, 'channel'] = channel\n",
    "    df.loc[:, 'stance'] = stance\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "channel = df_channels.iloc[i]['channel_name']    \n",
    "last_id = df_channels.iloc[i]['last_id']\n",
    "stance = df_channels.iloc[i]['stance']\n",
    "start_date = datetime.datetime(2023, 10, 1) # minimum date for TelegramClient\n",
    "\n",
    "#function to get new messages from channel\n",
    "async def get_new_messages(channel, last_id, start_date):\n",
    "    async with TelegramClient('session', api_id, api_hash) as client:\n",
    "        # COLLECT NEW MESSAGES\n",
    "        data = [] # for collecting new messages\n",
    "        # check if last_id is integer (=set)\n",
    "        try:\n",
    "            offset_id = int(last_id)\n",
    "        except:\n",
    "            offset_id = 0\n",
    "        async for message in client.iter_messages(channel, reverse=True, offset_id=offset_id, offset_date=start_date):\n",
    "            data.append(message.to_dict())\n",
    "        # if no new messages, skip\n",
    "    print(f\"Channel: {channel}, N of new messages: {len(data)}\")\n",
    "    if len(data) == 0:\n",
    "        return None\n",
    "    # create df from collected data\n",
    "    df = pd.DataFrame(data)\n",
    "    # process new messages\n",
    "    df = process_new_messages(df, channel, stance)\n",
    "    # return df\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = openai_key\n",
    "\n",
    "# function for openai embeddings\n",
    "def get_embeddings(text, model=\"text-embedding-ada-002\"):\n",
    "    response = openai.Embedding.create(\n",
    "        input=text,\n",
    "        model=model\n",
    "    )\n",
    "    embeddings = response['data'][0]['embedding']\n",
    "    print(f\"Embeddings shape: {len(embeddings)} for channel: {channel}\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel: rt_russian, N of new messages: 707\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "channel = df_channels.iloc[i]['channel_name']    \n",
    "last_id = df_channels.iloc[i]['last_id']\n",
    "stance = df_channels.iloc[i]['stance']\n",
    "df = await get_new_messages(channel, last_id)\n",
    "df['embeddings'] = df['summary'].apply(get_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date to integer (without time)\n",
    "df['date'] = df['date'].apply(lambda x: int(time.mktime(x.timetuple())))\n",
    "df['date'] = df['date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2fc6be4842f46e9a05d510de4338e40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_name='tg-news'\n",
    "batch_size=10\n",
    "\n",
    "for i in tqdm_notebook(range(0, df.shape[0], batch_size)):\n",
    "    # set end position of batch\n",
    "    i_end = min(i+batch_size, df.shape[0])\n",
    "    # get batch of IDs, embeds and metadata\n",
    "    ids_batch = df['id'][i: i_end]\n",
    "    embeds_batch = df['embeddings'][i: i_end]\n",
    "    # prep metadata: 'channel', 'date', 'message', 'views', 'cleaned_message', 'summary'\n",
    "    meta_cols = ['channel', 'stance', 'date', 'message', 'views', 'cleaned_message', 'summary']\n",
    "    meta_batch = df[meta_cols][i: i_end].to_dict(orient='records')\n",
    "    \n",
    "    # upsert to Pinecone \n",
    "    to_upsert = zip(ids_batch, embeds_batch, meta_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>stance</th>\n",
       "      <th>date</th>\n",
       "      <th>message</th>\n",
       "      <th>views</th>\n",
       "      <th>cleaned_message</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt_russian</td>\n",
       "      <td>tv</td>\n",
       "      <td>2023-10-22 15:15:36+00:00</td>\n",
       "      <td>Три украинские ракеты, летевшие в сторону Крым...</td>\n",
       "      <td>68235</td>\n",
       "      <td>Три украинские ракеты, летевшие в сторону Крым...</td>\n",
       "      <td>Три украинские ракеты, летевшие в сторону Крым...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt_russian</td>\n",
       "      <td>tv</td>\n",
       "      <td>2023-10-22 15:22:27+00:00</td>\n",
       "      <td>Волонтёры спасли более 100 собак от ужасных ус...</td>\n",
       "      <td>68211</td>\n",
       "      <td>Волонтёры спасли более 100 собак от ужасных ус...</td>\n",
       "      <td>Об «Островке надежды», который теперь называет...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt_russian</td>\n",
       "      <td>tv</td>\n",
       "      <td>2023-10-22 15:26:18+00:00</td>\n",
       "      <td>ЦАХАЛ заявил, что израильский танк случайно об...</td>\n",
       "      <td>70475</td>\n",
       "      <td>ЦАХАЛ заявил, что израильский танк случайно об...</td>\n",
       "      <td>ЦАХАЛ заявил, что израильский танк случайно об...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rt_russian</td>\n",
       "      <td>tv</td>\n",
       "      <td>2023-10-22 15:40:01+00:00</td>\n",
       "      <td>«Помогите нам, дайте нам попасть в Египет. Чег...</td>\n",
       "      <td>62104</td>\n",
       "      <td>«Помогите нам, дайте нам попасть в Египет. Чег...</td>\n",
       "      <td>Ни одному жителю сектора Газа с иностранным па...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt_russian</td>\n",
       "      <td>tv</td>\n",
       "      <td>2023-10-22 16:00:33+00:00</td>\n",
       "      <td>Госдеп США поручил части американского дипперс...</td>\n",
       "      <td>48859</td>\n",
       "      <td>Госдеп США поручил части американского дипперс...</td>\n",
       "      <td>Госдеп США поручил части американского дипперс...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rt_russian</td>\n",
       "      <td>tv</td>\n",
       "      <td>2023-10-22 16:09:05+00:00</td>\n",
       "      <td>Илон Маск заявил, что даст $1 млрд Википедии, ...</td>\n",
       "      <td>42780</td>\n",
       "      <td>Илон Маск заявил, что даст $1 млрд Википедии, ...</td>\n",
       "      <td>Илон Маск заявил, что даст $1 млрд Википедии, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rt_russian</td>\n",
       "      <td>tv</td>\n",
       "      <td>2023-10-22 16:29:58+00:00</td>\n",
       "      <td>В Москве задержали 31-летнего мужчину по делу ...</td>\n",
       "      <td>16274</td>\n",
       "      <td>В Москве задержали 31-летнего мужчину по делу ...</td>\n",
       "      <td>В Москве задержали 31-летнего мужчину по делу ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rt_russian</td>\n",
       "      <td>tv</td>\n",
       "      <td>2023-10-22 16:34:53+00:00</td>\n",
       "      <td>Египетские пограничники получили легкие ранени...</td>\n",
       "      <td>8139</td>\n",
       "      <td>Египетские пограничники получили легкие ранени...</td>\n",
       "      <td>Египетские пограничники получили легкие ранени...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      channel stance                      date  \\\n",
       "0  rt_russian     tv 2023-10-22 15:15:36+00:00   \n",
       "1  rt_russian     tv 2023-10-22 15:22:27+00:00   \n",
       "2  rt_russian     tv 2023-10-22 15:26:18+00:00   \n",
       "3  rt_russian     tv 2023-10-22 15:40:01+00:00   \n",
       "4  rt_russian     tv 2023-10-22 16:00:33+00:00   \n",
       "5  rt_russian     tv 2023-10-22 16:09:05+00:00   \n",
       "6  rt_russian     tv 2023-10-22 16:29:58+00:00   \n",
       "7  rt_russian     tv 2023-10-22 16:34:53+00:00   \n",
       "\n",
       "                                             message  views  \\\n",
       "0  Три украинские ракеты, летевшие в сторону Крым...  68235   \n",
       "1  Волонтёры спасли более 100 собак от ужасных ус...  68211   \n",
       "2  ЦАХАЛ заявил, что израильский танк случайно об...  70475   \n",
       "3  «Помогите нам, дайте нам попасть в Египет. Чег...  62104   \n",
       "4  Госдеп США поручил части американского дипперс...  48859   \n",
       "5  Илон Маск заявил, что даст $1 млрд Википедии, ...  42780   \n",
       "6  В Москве задержали 31-летнего мужчину по делу ...  16274   \n",
       "7  Египетские пограничники получили легкие ранени...   8139   \n",
       "\n",
       "                                     cleaned_message  \\\n",
       "0  Три украинские ракеты, летевшие в сторону Крым...   \n",
       "1  Волонтёры спасли более 100 собак от ужасных ус...   \n",
       "2  ЦАХАЛ заявил, что израильский танк случайно об...   \n",
       "3  «Помогите нам, дайте нам попасть в Египет. Чег...   \n",
       "4  Госдеп США поручил части американского дипперс...   \n",
       "5  Илон Маск заявил, что даст $1 млрд Википедии, ...   \n",
       "6  В Москве задержали 31-летнего мужчину по делу ...   \n",
       "7  Египетские пограничники получили легкие ранени...   \n",
       "\n",
       "                                             summary  \n",
       "0  Три украинские ракеты, летевшие в сторону Крым...  \n",
       "1  Об «Островке надежды», который теперь называет...  \n",
       "2  ЦАХАЛ заявил, что израильский танк случайно об...  \n",
       "3  Ни одному жителю сектора Газа с иностранным па...  \n",
       "4  Госдеп США поручил части американского дипперс...  \n",
       "5  Илон Маск заявил, что даст $1 млрд Википедии, ...  \n",
       "6  В Москве задержали 31-летнего мужчину по делу ...  \n",
       "7  Египетские пограничники получили легкие ранени...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(meta_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.init(api_key=pine_key, environment=pine_env)\n",
    "\n",
    "def upsert_embeddings_to_pinecone(df, index_name='tg-news', batch_size=10):\n",
    "    # connect to Pinecone index\n",
    "    index = pinecone.Index(index_name)\n",
    "    \n",
    "    # upsert embeddings in batches\n",
    "    for i in tqdm_notebook(range(0, df.shape[0], batch_size)):\n",
    "        # set end position of batch\n",
    "        i_end = min(i+batch_size, df.shape[0])\n",
    "        # get batch of IDs, embeds and metadata\n",
    "        ids_batch = df['id'][i: i_end]\n",
    "        embeds_batch = df['embeddings'][i: i_end]\n",
    "        # prep metadata: 'channel', 'date', 'message', 'views', 'cleaned_message', 'summary'\n",
    "        meta_cols = ['channel', 'stance', 'date', 'message', 'views', 'cleaned_message', 'summary']\n",
    "        meta_batch = df[meta_cols][i: i_end].to_dict(orient='records')\n",
    "        \n",
    "        # upsert to Pinecone \n",
    "        to_upsert = zip(ids_batch, embeds_batch, meta_batch)\n",
    "    index.upsert(vectors=list(to_upsert))\n",
    "    print(f\"Upserted {df.shape[0]} embeddings to Pinecone index {index_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need functions: \n",
    "1) get & process messages (clean, get summary)\n",
    "2) get openai embeds\n",
    "3) upsert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "channel = df_channels.iloc[i]['channel_name']    \n",
    "last_id = df_channels.iloc[i]['last_id']\n",
    "stance = df_channels.iloc[i]['stance']\n",
    "df = get_messages(channel, last_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = process_new_messages(df, channel, stance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over channels.csv and get last message_id for each channel\n",
    "df_channels = pd.read_csv('channels.csv')\n",
    "for i in tqdm_notebook(range(df_channels.shape[0])):\n",
    "    channel = df_channels.iloc[i]['channel']    \n",
    "    last_id = df_channels.iloc[i]['last_id']\n",
    "    stance = df_channels.iloc[i]['stance']\n",
    "    df = get_messages(channel, last_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ask_media",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
